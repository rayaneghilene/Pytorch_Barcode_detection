{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "mount_file_id": "15GK42fdTrTWQfOdrNz47TwvDK11u9c7h",
      "authorship_tag": "ABX9TyM9+eqXeypUEk2sxbSpvpSt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06a7a43214594d349a3f57c808d8dca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_84bc506c092044f68c3eac6f231b614b",
              "IPY_MODEL_ffab67ad15434b50a278e451a8b63992",
              "IPY_MODEL_28a0803187af454381b828eb2bb447b6"
            ],
            "layout": "IPY_MODEL_03962cc442bf4d029743261d94847d48"
          }
        },
        "84bc506c092044f68c3eac6f231b614b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_736f4ecc6c6c4a8a81232e139c322bee",
            "placeholder": "​",
            "style": "IPY_MODEL_e9892308b2054fad877caa01030ae2a6",
            "value": "Sanity Checking DataLoader 0:   0%"
          }
        },
        "ffab67ad15434b50a278e451a8b63992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14dfa9a417574d68aab70e3c3228f49d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e699197a92d431c8142183c3030872f",
            "value": 0
          }
        },
        "28a0803187af454381b828eb2bb447b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8870f59b2d3d42ab98892c2c87c5bae8",
            "placeholder": "​",
            "style": "IPY_MODEL_2e70ea1787fd4733b00092b6cf963604",
            "value": " 0/2 [00:00&lt;?, ?it/s]"
          }
        },
        "03962cc442bf4d029743261d94847d48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "736f4ecc6c6c4a8a81232e139c322bee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9892308b2054fad877caa01030ae2a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14dfa9a417574d68aab70e3c3228f49d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e699197a92d431c8142183c3030872f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8870f59b2d3d42ab98892c2c87c5bae8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e70ea1787fd4733b00092b6cf963604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rayaneghilene/Pytorch_Barcode_detection/blob/main/Barcode_detection_pytorch_lightning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning\n",
        "!pip install torch-summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t368bGZOVIsJ",
        "outputId": "5c68289f-5a4d-4e3f-efce-fa5c7a3f8e9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (2.0.9.post0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n",
            "Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.2.0)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.5.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (17.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->pytorch-lightning) (2.1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: torch-summary in /usr/local/lib/python3.10/dist-packages (1.4.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Barcode detection using CNN"
      ],
      "metadata": {
        "id": "4XyU0FUZJq7D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AtidZDRJpt8"
      },
      "outputs": [],
      "source": [
        "#Imports :\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.datasets import MNIST, CIFAR10\n",
        "from torchvision import transforms\n",
        "from torchvision import utils\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import skimage\n",
        "from skimage import io\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import torchvision.transforms as transform\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_lightning import loggers as pl_loggers\n",
        "import pytorch_lightning as pl\n",
        "import torchmetrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1- Exploring the data"
      ],
      "metadata": {
        "id": "5-0dMf5CKKMH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "The dataset used for this project is provided by the \"Applied Recognition Technology Laboratory Department of Theoretical and Applied Science\"\n",
        "\n",
        "*Neural Image Restoration For Decoding 1-D Barcodes Using Common Camera Phones\n",
        "Alessandro Zamberletti, Ignazio Gallo, Moreno Carullo and Elisabetta Binaghi\n",
        "Computer Vision, Imaging and Computer Graphics. Theory and Applications, Springer Berlin Heidelberg, 2011*\n",
        "\n",
        "The following dataset will be divided into three sets:\n",
        "\n",
        "- Training set is used to train the Model (i.e., to find the parameters of Model).\n",
        "- Validation set is used to watch the Model's training (to verify whether the training procedure goes well).\n",
        "- Test set is used to evaluate the performance of the Model (in our case, to measure if the model compresses and decompresses well new images)."
      ],
      "metadata": {
        "id": "r4CXC_TJKO-2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creation of the Dataset"
      ],
      "metadata": {
        "id": "4SPknfHwWqr-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating random barcodes"
      ],
      "metadata": {
        "id": "djNIc8lkoUNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-barcode opencv-python\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9_kjXhIiMQZ",
        "outputId": "a88a5819-10bf-4925-dc97-adce96465df2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-barcode\n",
            "  Downloading python_barcode-0.15.1-py3-none-any.whl (212 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/213.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m204.8/213.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n",
            "Installing collected packages: python-barcode\n",
            "Successfully installed python-barcode-0.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import barcode\n",
        "from barcode import generate\n",
        "from barcode.writer import ImageWriter\n",
        "\n",
        "# Define your dataset directory\n",
        "dataset_dir = '/content/generated_barcodes'\n",
        "\n",
        "# Create the output directory for generated barcodes and annotations\n",
        "if not os.path.exists(dataset_dir):\n",
        "    os.makedirs(dataset_dir)\n",
        "\n",
        "# Number of random barcodes to generate\n",
        "num_barcodes = 1000\n",
        "\n",
        "# Define barcode symbology (EAN-13, UPC-A, etc.)\n",
        "barcode_symbology = 'ean13'\n",
        "\n",
        "# Generate random barcodes and annotations\n",
        "for i in range(num_barcodes):\n",
        "    barcode_number = np.random.randint(100000000000, 999999999999)  # Generate a random 12-digit barcode number\n",
        "    barcode_filename = f'barcode_{i}.png'\n",
        "    barcode_filepath = os.path.join(dataset_dir, barcode_filename)\n",
        "\n",
        "    # Generate barcode image\n",
        "    with open(barcode_filepath, 'wb') as barcode_file:\n",
        "        generate(barcode_symbology, str(barcode_number), writer=ImageWriter(), output=barcode_file)\n",
        "\n",
        "    # Save annotation to annotation file\n",
        "    annotation_filename = f'annotations.txt'\n",
        "    annotation_filepath = os.path.join(dataset_dir, annotation_filename)\n",
        "    with open(annotation_filepath, 'a') as annotation_file:\n",
        "        annotation_file.write(f'{barcode_filename}: {barcode_number}\\n')\n",
        "\n",
        "    # Display the generated barcode\n",
        "\n",
        "\n",
        "print(\"Random barcode generation and annotation completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdJVVoRZmGNw",
        "outputId": "58c59671-47e3-4908-cf82-8fae610f29ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random barcode generation and annotation completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating the dataset"
      ],
      "metadata": {
        "id": "pZGx9805oXqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imgaug\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vC9VEXxUpqz3",
        "outputId": "d634afd9-2320-4865-f601-c01455fe81bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from imgaug) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imgaug) (1.11.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from imgaug) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug) (3.7.1)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.10/dist-packages (from imgaug) (0.19.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from imgaug) (4.8.0.76)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug) (2.31.5)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from imgaug) (2.0.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug) (3.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug) (2023.9.26)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.14.2->imgaug) (23.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug) (0.12.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug) (4.43.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug) (2.8.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "\n",
        "# Define your dataset directory\n",
        "dataset_dir = '/content/generated_barcodes'\n",
        "\n",
        "\n",
        "\n",
        "# Custom dataset class\n",
        "class BarcodeDataset(Dataset):\n",
        "    def __init__(self, dataset_dir, transform=None):\n",
        "        self.dataset_dir = dataset_dir\n",
        "        self.data = []\n",
        "        self.transform = transform\n",
        "\n",
        "        # # Step 1: Load Images (without cropping and preprocessing)\n",
        "        # for image_filename in os.listdir(dataset_dir):\n",
        "        #     if image_filename.endswith('.png'):\n",
        "        #         barcode_number = os.path.splitext(image_filename)[0]\n",
        "        #         image_path = os.path.join(dataset_dir, image_filename)\n",
        "\n",
        "        #         # Load image in grayscale\n",
        "        #         image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        #         # Add the sample to the dataset\n",
        "        #         self.data.append({\n",
        "        #             'image': image,\n",
        "        #             'barcode_number': barcode_number\n",
        "        #         })\n",
        "class BarcodeDataset(Dataset):\n",
        "    def __init__(self, dataset_dir, transform=None):\n",
        "        self.dataset_dir = dataset_dir\n",
        "        self.data = []\n",
        "        self.label_map = {}  # Mapping from barcode number to unique integer label\n",
        "        self.label_counter = 0  # Counter to assign unique labels\n",
        "        self.transform = transform\n",
        "        # Step 1: Load Images (without cropping and preprocessing)\n",
        "        for image_filename in os.listdir(dataset_dir):\n",
        "            if image_filename.endswith('.png'):\n",
        "                barcode_number = os.path.splitext(image_filename)[0]\n",
        "                if barcode_number not in self.label_map:\n",
        "                    self.label_map[barcode_number] = self.label_counter\n",
        "                    self.label_counter += 1\n",
        "\n",
        "                image_path = os.path.join(dataset_dir, image_filename)\n",
        "\n",
        "                # Load image in grayscale\n",
        "                image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "                # Add the sample to the dataset\n",
        "                self.data.append({\n",
        "                    'image': image,\n",
        "                    'label': self.label_map[barcode_number]  # Use the integer label\n",
        "                })\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        image = sample['image']\n",
        "        label = sample['label']  # Integer label\n",
        "\n",
        "        # Apply the specified transforms if provided\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # Convert the label to a Tensor\n",
        "        label = torch.tensor(label, dtype=torch.int64)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "\n",
        "\n",
        "# Define transformations to apply to the images\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((224, 224)),  # Resize the image to the desired size\n",
        "    transforms.ToTensor(),  # Convert to tensor\n",
        "])\n",
        "\n",
        "# Create an instance of your custom dataset with transforms\n",
        "barcode_dataset = BarcodeDataset(dataset_dir, transform=transform)\n",
        "\n",
        "# Split the dataset into training and testing (validation) sets\n",
        "train_size = int(0.8 * len(barcode_dataset))\n",
        "test_size = len(barcode_dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(barcode_dataset, [train_size, test_size])\n",
        "\n",
        "# Create DataLoaders for training and testing\n",
        "batch_size = 32\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# You can now use train_dataloader and test_dataloader for training and testing, respectively\n"
      ],
      "metadata": {
        "id": "7tBkJCiOq-y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Spliting the data into three sets :Training, Testing and Validation"
      ],
      "metadata": {
        "id": "aIUQjLblo6-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into training and remaining data\n",
        "train_data, test_data = train_test_split(barcode_dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Split remaining data into testing and validation sets\n",
        "# test_data, val_data = train_test_split(remaining_data, test_size=0.5, random_state=42)\n",
        "\n",
        "# Print the sizes of each set\n",
        "print(\"Train set size:\", len(train_data))\n",
        "print(\"Test set size:\", len(test_data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1P40g0CoPgw",
        "outputId": "398ff1bf-7385-4498-a1a2-c2c1402e2a75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 800\n",
            "Test set size: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Retrieve one sample of the Dataset.\n",
        "sample = train_data[0]\n",
        "\n",
        "# TODO : What is in a sample ? Print the sample to understand\n",
        "# print(sample)\n",
        "\n",
        "image, label =sample\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.imshow(image.permute(1,2,0), cmap='gray')  # Adjust the colormap as needed\n",
        "plt.title(f\"Label: {label}\")\n",
        "plt.show()\n",
        "print(image.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "M45KnfJ7pCXO",
        "outputId": "dc771a27-e27e-4678-a536-d378df407ba9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch Lightning"
      ],
      "metadata": {
        "id": "7JXeZQwGopu9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lightning Data Module"
      ],
      "metadata": {
        "id": "PFv5uH1jpcWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import TRUE\n",
        "from torchvision.datasets.fakedata import FakeData\n",
        "class BarcodeDataModule(pl.LightningDataModule):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "        self.data_dir = ''\n",
        "        self.batch_size_train, self.batch_size_valid, self.batch_size_test = 32,32,32\n",
        "\n",
        "    def prepare_data(self):\n",
        "        # TODO : load the train and test dataset\n",
        "        train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "        test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "    def setup(self, stage):\n",
        "        #We need to setup our module. We have a training set that we will be fitting in our model\n",
        "        #and a testing set used to test our models prediction.\n",
        "        #the stage variable corresponds to those two steps :\n",
        "        #         |fit\n",
        "        # stage = <test\n",
        "        #         |None\n",
        "\n",
        "        #First stage is 'fit' (or None)\n",
        "        if stage == \"fit\" or stage is None:\n",
        "            # We create a validation split to watch the training.\n",
        "            # TODO : Which dataset do we load for training ?\n",
        "            barcode_dataset = BarcodeDataset(dataset_dir)\n",
        "            train_size = int(0.8 * len(barcode_dataset))\n",
        "            test_size = len(barcode_dataset) - train_size\n",
        "            train_dataset, valid_dataset = random_split(barcode_dataset, [train_size, test_size])\n",
        "            # Assign the datasets as attributes of the module\n",
        "            self.train_data = train_data\n",
        "            self.valid_dataset = valid_dataset\n",
        "\n",
        "\n",
        "            #self.mnist_train = FashionMNIST(self.data_dir, train =False, transform=self.transform)\n",
        "\n",
        "        #Second stage is 'test'\n",
        "        if stage == \"test\" or stage is None:\n",
        "\n",
        "            self.test_data = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "            # Question : What additional set can we create ? Why ?\n",
        "\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        train_loader =  DataLoader(self.train_data, batch_size=batch_size, shuffle=True)\n",
        "        return train_loader\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        # TODO : Now create your Validation DataLoader\n",
        "        val_loader =  DataLoader(self.valid_dataset, batch_size=batch_size, shuffle=True)\n",
        "        return val_loader\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        # TODO : Now create your Testing DataLoader\n",
        "        test_loader =  DataLoader(self.test_data, batch_size=batch_size, shuffle=True)\n",
        "        return test_loader\n"
      ],
      "metadata": {
        "id": "PaBr2Ez_pfTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets.fakedata import FakeData  # This import doesn't seem to be used\n",
        "\n",
        "class BarcodeDataModule(pl.LightningDataModule):\n",
        "\n",
        "    def __init__(self, dataset_dir, batch_size=32):\n",
        "        super().__init__()\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
        "        self.dataset_dir = dataset_dir\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def prepare_data(self):\n",
        "        # TODO : load the train and test dataset\n",
        "        train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "        test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    def setup(self, stage):\n",
        "        # Load and split your dataset during setup\n",
        "        if stage == \"fit\" or stage is None:\n",
        "            # Create a custom BarcodeDataset if not already defined\n",
        "            barcode_dataset = BarcodeDataset(self.dataset_dir, transform=self.transform)\n",
        "            dataset_size = len(barcode_dataset)\n",
        "            train_size = int(0.8 * dataset_size)\n",
        "            val_size = dataset_size - train_size\n",
        "\n",
        "            # Split the dataset into training and validation sets\n",
        "            self.train_dataset, self.valid_dataset = random_split(barcode_dataset, [train_size, val_size])\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        # Return the DataLoader for the training set\n",
        "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        # Return the DataLoader for the validation set\n",
        "        return DataLoader(self.valid_dataset, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        # Create and return a DataLoader for your testing set\n",
        "        # Assuming you have a test dataset in BarcodeDataset format\n",
        "        test_dataset = BarcodeDataset(self.dataset_dir, transform=self.transform, train=False)\n",
        "        return DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "aw7wRiic5cXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lightning Module"
      ],
      "metadata": {
        "id": "-XfHLZw3xZim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "class BarcodeClassifier(pl.LightningModule):\n",
        "    def __init__(self, output_shape, input_channels=1):\n",
        "        super(BarcodeClassifier, self).__init__()\n",
        "        self.output_shape = output_shape\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        # Define your model architecture\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3),  # Input channels should be 1\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=3),\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(509312, 128),  # Adjust the input size based on your image dimensions\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, output_shape)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x)\n",
        "        return x\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = optim.SGD(self.parameters(), lr=0.001, momentum=0.9)\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        x1 = self(x)\n",
        "        y = y.long()\n",
        "        loss = nn.functional.cross_entropy(x1, y)\n",
        "\n",
        "        predictions = torch.argmax(x1, dim=1)\n",
        "        correct = (predictions == y).sum().item()\n",
        "        acc = correct / len(y)\n",
        "\n",
        "        self.log('train_loss', loss)\n",
        "        self.log('train_acc', acc)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        x1 = self(x)\n",
        "\n",
        "        loss = nn.functional.cross_entropy(x1, y)\n",
        "\n",
        "        predictions = torch.argmax(x1, dim=1)\n",
        "        correct = (predictions == y).sum().item()\n",
        "        acc = correct / len(y)\n",
        "\n",
        "        self.log('val_loss', loss)\n",
        "        self.log('val_acc', acc)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        x1 = self(x)\n",
        "\n",
        "        loss = nn.functional.cross_entropy(x1, y)\n",
        "\n",
        "        predictions = torch.argmax(x1, dim=1)\n",
        "        correct = (predictions == y).sum().item()\n",
        "        acc = correct / len(y)\n",
        "        self.acc = acc\n",
        "\n",
        "        self.log('test_loss', loss)\n",
        "        self.log('test_acc', acc)\n",
        "\n",
        "\n",
        "# def training_step(self, batch, batch_idx):\n",
        "#     x, y = batch\n",
        "#     x1 = self(x)\n",
        "\n",
        "#     loss = nn.functional.cross_entropy(x1, y)\n",
        "\n",
        "#     predictions = torch.argmax(x1, dim=1)\n",
        "#     correct = (predictions == y).sum().item()\n",
        "#     acc = correct / len(y)\n",
        "\n",
        "#     self.log('train_loss', loss)\n",
        "#     self.log('train_acc', acc)\n",
        "#     return {\"loss\": loss, \"acc\": acc}\n",
        "\n",
        "    def test_epoch_start(self):\n",
        "        self.acc = 0\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        self.log('Final Accuracy', self.acc)\n"
      ],
      "metadata": {
        "id": "gZ3Is_aYthPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lightning Training"
      ],
      "metadata": {
        "id": "Ra3DmLwTxcc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Train\n",
        "tb_logger = pl_loggers.TensorBoardLogger(\"Barcode detection model\")\n",
        "\n",
        "dm1 = BarcodeDataModule(dataset_dir='/content/generated_barcodes')\n",
        "model1 = BarcodeClassifier(10)\n",
        "# accel = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "trainer = pl.Trainer(max_epochs=10,accelerator='cpu',logger=tb_logger)\n",
        "trainer.fit(model1, dm1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "06a7a43214594d349a3f57c808d8dca9",
            "84bc506c092044f68c3eac6f231b614b",
            "ffab67ad15434b50a278e451a8b63992",
            "28a0803187af454381b828eb2bb447b6",
            "03962cc442bf4d029743261d94847d48",
            "736f4ecc6c6c4a8a81232e139c322bee",
            "e9892308b2054fad877caa01030ae2a6",
            "14dfa9a417574d68aab70e3c3228f49d",
            "1e699197a92d431c8142183c3030872f",
            "8870f59b2d3d42ab98892c2c87c5bae8",
            "2e70ea1787fd4733b00092b6cf963604"
          ]
        },
        "id": "Q5nVnZMRuN8v",
        "outputId": "c16814f4-5f79-4b27-c99e-72fc751c0702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: False\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/setup.py:176: PossibleUserWarning: GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
            "  rank_zero_warn(\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name  | Type       | Params\n",
            "-------------------------------------\n",
            "0 | model | Sequential | 65.2 M\n",
            "-------------------------------------\n",
            "65.2 M    Trainable params\n",
            "0         Non-trainable params\n",
            "65.2 M    Total params\n",
            "260.775   Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06a7a43214594d349a3f57c808d8dca9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-f333770ece3b>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# accel = 'cuda' if torch.cuda.is_available() else 'cpu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtb_logger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lightning_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0m_verify_strategy_supports_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         )\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;31m# RUN THE TRAINER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0misolate_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;31m# run eval step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m             \u001b[0mval_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m             \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_callback_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"on_sanity_check_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/utilities.py\u001b[0m in \u001b[0;36m_decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mcontext_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcontext_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mloop_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/evaluation_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0mprevious_dataloader_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;31m# run step hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0;31m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/evaluation_loop.py\u001b[0m in \u001b[0;36m_evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0mhook_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"test_step\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"validation_step\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_strategy_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstep_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_progress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mincrement_processed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Strategy]{trainer.strategy.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;31m# restore current_fx when nested context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/strategy.py\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValidationStep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSTEP_OUTPUT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-a68d0ec16bb0>\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3029\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Target 466 is out of bounds."
          ]
        }
      ]
    }
  ]
}